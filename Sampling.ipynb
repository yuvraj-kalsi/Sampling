{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = pd.read_csv(\"Creditcard_data.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling to Balance the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "df_resampled = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled)], axis=1)\n",
    "df_resampled.columns = df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    763\n",
      "1      9\n",
      "Name: Class, dtype: int64\n",
      "0    763\n",
      "1    763\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Class'].value_counts())\n",
    "print(df_resampled['Class'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_random_sample(df, z_score, margin_error, p):\n",
    "\n",
    "    n = (z_score**2 * p * (1-p)) / margin_error**2\n",
    "\n",
    "    n = int(np.ceil(n))\n",
    "    \n",
    "    sample_indices = random.sample(range(len(df)), n)\n",
    "\n",
    "    sample_df = df.iloc[sample_indices, :]\n",
    "    \n",
    "    return sample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(385, 31)\n"
     ]
    }
   ],
   "source": [
    "sample_1 = simple_random_sample(df_resampled, 1.96, 0.05, 0.5)\n",
    "print(sample_1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systematic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def systematic_sample(df, k):\n",
    "   \n",
    "    start_indices = np.arange(0, len(df), k)\n",
    "    \n",
    "    sample_df = df.iloc[start_indices, :]\n",
    "    \n",
    "    return sample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 31)\n"
     ]
    }
   ],
   "source": [
    "sample_2 = systematic_sample(df_resampled, 5)\n",
    "print(sample_2.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(df, col, z, e, p):\n",
    "    \n",
    "    t = df[col].value_counts()\n",
    "\n",
    "    s = len(t)\n",
    "    n = (z ** 2) * (p * (1 - p)) // ((e / s) ** 2)\n",
    "    \n",
    "    n_rows = t[0] + t[1]\n",
    "\n",
    "    sample_df = df.groupby(col, group_keys=False).apply(lambda x: x.sample(frac = n/n_rows))\n",
    "    \n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 31)\n"
     ]
    }
   ],
   "source": [
    "sample_3 = stratified_sample(df_resampled, 'Class', 0.95, 0.05, 0.5)\n",
    "print(sample_3.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sampling(df, z, e, p, c):\n",
    "    \n",
    "    n = ((z ** 2) * (p * (1 - p)) // ((e) ** 2)) / (df.shape[0] - c)\n",
    "\n",
    "    cluster_sample_df = df.sample(frac = n)\n",
    "    \n",
    "    return cluster_sample_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 31)\n"
     ]
    }
   ],
   "source": [
    "sample_4 = cluster_sampling(df_resampled, 0.95, 0.05, 0.5, 300)\n",
    "print(sample_4.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quota Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quota_sampling(df, strata, quotas):\n",
    "\n",
    "    sample = pd.DataFrame(columns = df.columns)\n",
    "\n",
    "    for stratum, quota in quotas.items():\n",
    "\n",
    "        stratum_df = df[df[strata] == stratum]\n",
    "\n",
    "        stratum_sample = stratum_df.sample(n = quota, random_state = 1)\n",
    "        \n",
    "        sample = pd.concat([sample, stratum_sample], ignore_index = True)\n",
    "    \n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 31)\n"
     ]
    }
   ],
   "source": [
    "quotas = {0: 50, 1: 50}\n",
    "sample_5 = quota_sampling(df_resampled, 'Class', quotas)\n",
    "print(sample_5.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = [sample_1, sample_2, sample_3, sample_4, sample_5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(df.drop('Class', axis=1))\n",
    "y_test = np.array(df['Class']).reshape(-1,).astype('int')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 1 : LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "M1 = []\n",
    "for sample in all_samples:\n",
    "\n",
    "    X_train = np.array(sample.iloc[:,:-1])\n",
    "    y_train = np.array(sample.iloc[:,-1:].values).reshape(-1,).astype('int')\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    M1.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8354922279792746, 0.8095854922279793, 0.8432642487046632, 0.7681347150259067, 0.822538860103627]\n"
     ]
    }
   ],
   "source": [
    "print(M1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 2 : RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "M2 = []\n",
    "for sample in all_samples:\n",
    "    \n",
    "    X_train = np.array(sample.iloc[:,:-1])\n",
    "    y_train = np.array(sample.iloc[:,-1:].values).reshape(-1,).astype('int')\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    M2.append(accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9961139896373057, 0.9961139896373057, 0.9974093264248705, 0.9766839378238342, 0.9740932642487047]\n"
     ]
    }
   ],
   "source": [
    "print(M2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 3 : SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "M3 = []\n",
    "for sample in all_samples:\n",
    "\n",
    "    X_train = np.array(sample.iloc[:,:-1])\n",
    "    y_train = np.array(sample.iloc[:,-1:].values).reshape(-1,).astype('int')\n",
    "    \n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    M3.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6230569948186528, 0.7020725388601037, 0.694300518134715, 0.7046632124352331, 0.7551813471502591]\n"
     ]
    }
   ],
   "source": [
    "print(M3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 4 : GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "M4 = []\n",
    "for sample in all_samples:\n",
    "\n",
    "    X_train = np.array(sample.iloc[:,:-1])\n",
    "    y_train = np.array(sample.iloc[:,-1:].values).reshape(-1,).astype('int')\n",
    "    \n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    M4.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9702072538860104, 0.9922279792746114, 0.9909326424870466, 0.9546632124352331, 0.9183937823834197]\n"
     ]
    }
   ],
   "source": [
    "print(M4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - 5 : NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "M5 = []\n",
    "for sample in all_samples:\n",
    "    \n",
    "    X_train = np.array(sample.iloc[:,:-1])\n",
    "    y_train = np.array(sample.iloc[:,-1:].values).reshape(-1,).astype('int')\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    M5.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8898963730569949, 0.7914507772020726, 0.8937823834196891, 0.716321243523316, 0.9261658031088082]\n"
     ]
    }
   ],
   "source": [
    "print(M5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Simple Random Sampling</th>\n",
       "      <th>Systematic Sampling</th>\n",
       "      <th>Stratified Sampling</th>\n",
       "      <th>Cluster Sampling</th>\n",
       "      <th>Quota Sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.835492</td>\n",
       "      <td>0.809585</td>\n",
       "      <td>0.843264</td>\n",
       "      <td>0.768135</td>\n",
       "      <td>0.822539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.996114</td>\n",
       "      <td>0.996114</td>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.976684</td>\n",
       "      <td>0.974093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.623057</td>\n",
       "      <td>0.702073</td>\n",
       "      <td>0.694301</td>\n",
       "      <td>0.704663</td>\n",
       "      <td>0.755181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.970207</td>\n",
       "      <td>0.992228</td>\n",
       "      <td>0.990933</td>\n",
       "      <td>0.954663</td>\n",
       "      <td>0.918394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.889896</td>\n",
       "      <td>0.791451</td>\n",
       "      <td>0.893782</td>\n",
       "      <td>0.716321</td>\n",
       "      <td>0.926166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Simple Random Sampling  Systematic Sampling  \\\n",
       "Logistic Regression                0.835492             0.809585   \n",
       "Random Forest                      0.996114             0.996114   \n",
       "SVM                                0.623057             0.702073   \n",
       "Gradient Boosting                  0.970207             0.992228   \n",
       "Naive Bayes                        0.889896             0.791451   \n",
       "\n",
       "                     Stratified Sampling  Cluster Sampling  Quota Sampling  \n",
       "Logistic Regression             0.843264          0.768135        0.822539  \n",
       "Random Forest                   0.997409          0.976684        0.974093  \n",
       "SVM                             0.694301          0.704663        0.755181  \n",
       "Gradient Boosting               0.990933          0.954663        0.918394  \n",
       "Naive Bayes                     0.893782          0.716321        0.926166  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [M1, M2, M3, M4, M5]\n",
    "\n",
    "Comparison = pd.DataFrame(models, columns = ['Simple Random Sampling', 'Systematic Sampling', 'Stratified Sampling', 'Cluster Sampling',\n",
    "'Quota Sampling'])\n",
    "\n",
    "Comparison.index = ['Logistic Regression', 'Random Forest', 'SVM', 'Gradient Boosting', 'Naive Bayes']\n",
    "\n",
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sample created from 'Stratified Sampling' Technique gives the highest accuracy on model 'Random Forest' of 0.9974093264248705\n"
     ]
    }
   ],
   "source": [
    "max_value = Comparison.max().max()\n",
    "row, col = Comparison.stack().idxmax()\n",
    "print(f\"The Sample created from '{col}' Technique gives the highest accuracy on model '{row}' of {max_value}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f6a27bcfbe46a917dbd192f4a82657396dda26148bae633192e8d28c70725f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
